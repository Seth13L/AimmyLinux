name: Validate model submissions

on:
  pull_request_target:
    types: [opened, synchronize, reopened]
    paths:
      - 'models/**'
      - 'configs/**'

permissions:
  contents: write
  pull-requests: write

jobs:
  validate:
    runs-on: ubuntu-latest

    steps:
      - name: Get changed files
        id: changes
        uses: actions/github-script@v7
        with:
          script: |
            const { data: files } = await github.rest.pulls.listFiles({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              per_page: 100
            });

            const changed = files.map(f => f.filename);
            const hasModels = changed.some(f => f.startsWith('models/') && f.endsWith('.onnx'));
            const hasConfigs = changed.some(f => f.startsWith('configs/') && f.endsWith('.cfg'));

            core.setOutput('files', changed.join('\n'));
            core.setOutput('has_models', hasModels);
            core.setOutput('has_configs', hasConfigs);

            console.log('Changed files:', changed);

      - name: Handle wrong file types
        if: steps.changes.outputs.has_models == 'false' && steps.changes.outputs.has_configs == 'false'
        uses: actions/github-script@v7
        with:
          script: |
            const files = `${{ steps.changes.outputs.files }}`.trim().split('\n');
            const invalidFiles = files.filter(f => f.startsWith('models/') || f.startsWith('configs/'));
            const fileList = invalidFiles.map(f => '`' + f + '`').join(', ');

            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              labels: ['invalid']
            });

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## ❌ Invalid File Types

No valid \`.onnx\` or \`.cfg\` files found.

**Files uploaded:** ${fileList}

**Required:**
- Models: \`.onnx\` files in \`models/\` folder
- Configs: \`.cfg\` files in \`configs/\` folder

This PR has been automatically closed.`
            });

            await github.rest.pulls.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              state: 'closed'
            });

            core.setFailed('Invalid file types');

      - name: Checkout PR content
        if: steps.changes.outputs.has_models == 'true' || steps.changes.outputs.has_configs == 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Set up Python
        if: steps.changes.outputs.has_models == 'true' || steps.changes.outputs.has_configs == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install ONNX
        if: steps.changes.outputs.has_models == 'true'
        run: pip install onnx

      - name: Validate ONNX models
        id: validate
        if: steps.changes.outputs.has_models == 'true'
        run: |
          python << 'EOF'
          import onnx, sys, hashlib, json, os
          from pathlib import Path

          MIN_SIZE = 5 * 1024 * 1024
          MAX_SIZE = 50 * 1024 * 1024

          changed = """${{ steps.changes.outputs.files }}""".strip().split("\n")
          models = [f for f in changed if f.startswith("models/") and f.endswith(".onnx")]

          # Get hashes of existing models for duplicate check
          existing_hashes = {}
          for existing in Path("models").glob("*.onnx"):
              if str(existing) not in models:
                  existing_hashes[hashlib.sha256(existing.read_bytes()).hexdigest()] = existing.name

          def dim(d):
              return d.dim_value if d.dim_value > 0 else None

          results = []
          errors = []

          for model_path in models:
              p = Path(model_path)
              info = {"name": p.name, "errors": []}

              if not p.exists():
                  info["errors"].append("File not found")
                  errors.append(f"{p.name}: File not found")
                  results.append(info)
                  continue

              size = p.stat().st_size
              size_mb = size / 1024 / 1024
              info["size"] = f"{size_mb:.2f} MB"

              if size < MIN_SIZE:
                  info["errors"].append(f"Too small ({size_mb:.1f}MB < 5MB)")
                  errors.append(f"{p.name}: Too small")
              elif size > MAX_SIZE:
                  info["errors"].append(f"Too large ({size_mb:.1f}MB > 50MB)")
                  errors.append(f"{p.name}: Too large")

              # Duplicate check
              file_hash = hashlib.sha256(p.read_bytes()).hexdigest()
              info["hash"] = file_hash[:12]
              if file_hash in existing_hashes:
                  info["duplicate_of"] = existing_hashes[file_hash]
                  info["errors"].append(f"Duplicate of {existing_hashes[file_hash]}")
                  errors.append(f"{p.name}: Duplicate")
              else:
                  info["duplicate_of"] = None

              try:
                  model = onnx.load(str(p))
                  g = model.graph

                  in_dims = [dim(d) for d in g.input[0].type.tensor_type.shape.dim]
                  out_dims = [dim(d) for d in g.output[0].type.tensor_type.shape.dim]

                  info["input_shape"] = str(in_dims)
                  info["output_shape"] = str(out_dims)

                  # Extract resolution from input
                  if len(in_dims) == 4 and in_dims[2] and in_dims[3]:
                      info["resolution"] = f"{in_dims[2]}x{in_dims[3]}"
                  else:
                      info["resolution"] = "dynamic"

                  if len(g.input) != 1:
                      info["errors"].append("Must have 1 input")
                      errors.append(f"{p.name}: Invalid inputs")
                  elif len(in_dims) != 4 or in_dims[1] != 3:
                      info["errors"].append("Input must be [B,3,H,W]")
                      errors.append(f"{p.name}: Invalid input shape")

                  if len(g.output) != 1:
                      info["errors"].append("Must have 1 output")
                      errors.append(f"{p.name}: Invalid outputs")
                  elif len(out_dims) != 3 or (out_dims[1] and out_dims[1] < 5):
                      info["errors"].append("Output must be [B,>=5,N]")
                      errors.append(f"{p.name}: Invalid output shape")

              except Exception as e:
                  info["errors"].append(f"Invalid ONNX: {e}")
                  errors.append(f"{p.name}: Invalid ONNX")

              results.append(info)

          # Write results for comment step
          with open("validation_results.json", "w") as f:
              json.dump(results, f)

          if errors:
              print("Validation errors:")
              for e in errors:
                  print(f"  ::error::{e}")
              sys.exit(1)

          print(f"✓ {len(models)} model(s) validated")
          EOF

      - name: Validate configs
        if: steps.changes.outputs.has_configs == 'true'
        run: |
          python << 'EOF'
          import json
          import sys
          from pathlib import Path

          changed = """${{ steps.changes.outputs.files }}""".strip().split("\n")
          configs = [f for f in changed if f.startswith("configs/") and f.endswith(".cfg")]

          for cfg_path in configs:
              p = Path(cfg_path)
              print(f"Validating: {p.name}")

              if not p.exists():
                  print(f"::error::Config file not found: {p}")
                  sys.exit(1)

              if p.stat().st_size == 0:
                  print(f"::error::Empty config file: {p.name}")
                  sys.exit(1)

              try:
                  data = json.loads(p.read_text())
              except json.JSONDecodeError as e:
                  print(f"::error::Invalid JSON in {p.name}: {e}")
                  sys.exit(1)

              if not isinstance(data, dict):
                  print(f"::error::Config must be a JSON object: {p.name}")
                  sys.exit(1)

              print(f"  Keys: {len(data)}")
              print(f"  ✓ Valid config")

          print(f"✓ {len(configs)} config(s) validated")
          EOF

      - name: Apply labels
        if: always() && (steps.changes.outputs.has_models == 'true' || steps.changes.outputs.has_configs == 'true')
        uses: actions/github-script@v7
        with:
          script: |
            const hasModels = '${{ steps.changes.outputs.has_models }}' === 'true';
            const hasConfigs = '${{ steps.changes.outputs.has_configs }}' === 'true';
            const passed = '${{ job.status }}' === 'success';

            const add = [];
            const remove = [];

            if (hasModels) {
              add.push(passed ? 'model:valid' : 'model:invalid');
              remove.push(passed ? 'model:invalid' : 'model:valid');
            }
            if (hasConfigs) {
              add.push(passed ? 'config:valid' : 'config:invalid');
              remove.push(passed ? 'config:invalid' : 'config:valid');
            }

            for (const label of remove) {
              try {
                await github.rest.issues.removeLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  name: label
                });
              } catch (e) {}
            }

            if (add.length) {
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                labels: add
              });
            }

      - name: Post validation comment
        if: always() && steps.changes.outputs.has_models == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const passed = '${{ job.status }}' === 'success';

            let results = [];
            try {
              results = JSON.parse(fs.readFileSync('validation_results.json', 'utf8'));
            } catch (e) {
              console.log('No validation results file found');
              return;
            }

            const icon = passed ? '✅' : '❌';
            const status = passed ? 'Passed' : 'Failed';

            let body = `## ${icon} Model Validation ${status}\n\n`;

            for (const model of results) {
              const modelIcon = model.errors.length === 0 ? '✅' : '❌';
              body += `### ${modelIcon} \`${model.name}\`\n\n`;
              body += `| Property | Value |\n`;
              body += `|----------|-------|\n`;

              if (model.size) body += `| **Size** | ${model.size} |\n`;
              if (model.resolution) body += `| **Resolution** | ${model.resolution} |\n`;
              if (model.input_shape) body += `| **Input Shape** | \`${model.input_shape}\` |\n`;
              if (model.output_shape) body += `| **Output Shape** | \`${model.output_shape}\` |\n`;
              if (model.hash) body += `| **Hash** | \`${model.hash}\` |\n`;
              body += `| **Duplicate** | ${model.duplicate_of ? `⚠️ Yes (${model.duplicate_of})` : '✅ No'} |\n`;

              if (model.errors.length > 0) {
                body += `\n**Errors:**\n`;
                for (const err of model.errors) {
                  body += `- ❌ ${err}\n`;
                }
              }

              body += `\n`;
            }

            if (!passed) {
              body += `---\n⚠️ Please fix the issues above and push again.\n`;
            }

            // Find and update existing bot comment or create new one
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const botComment = comments.data.find(c => 
              c.user.type === 'Bot' && c.body.includes('Model Validation')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }

      - name: Auto-merge valid submissions
        if: success() && (steps.changes.outputs.has_models == 'true' || steps.changes.outputs.has_configs == 'true')
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.issue.number;

            // Merge the PR
            try {
              await github.rest.pulls.merge({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                merge_method: 'squash',
                commit_title: `Add community model/config (#${prNumber})`
              });

              console.log(`PR #${prNumber} merged successfully`);

              // Add merged comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: `## ✅ Merged!\n\nThank you for your contribution! Your submission has been validated and automatically merged.`
              });
            } catch (e) {
              console.log(`Could not auto-merge: ${e.message}`);
              // If merge fails (conflicts, branch protection, etc), just leave it for manual review
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                labels: ['needs-manual-merge']
              });
            }
